---
layout: research
title:  "Design for Virtuosity"
tag: ["augmented-instruments", "musician-studies"]
tagline: An ongoing body of research
thumb: virtuosity/virtuosity-thumb.jpg
main-image: /images/stock/06.jpg
production-date: 2017-2019
para: "Design for virtuosity: How expert musical skills can be repurposed in the design of new instruments."
authors: ["Andrew McPherson", "Fabio Morreale", "Kurijn Buys", "Jack Armitage"]
---

Musical performers spend many years achieving proficiency on their instruments. Newly created digital musical instruments (DMIs) face a significant barrier to adoption in that few performers are willing to repeat these years of training to develop expertise on an unknown instrument. Without expert players, evaluating the success of a DMI design is challenging, and establishing its place in a broader musical community is nearly impossible. As a result, while many digital instruments have been created over the past decade, few have achieved lasting impact beyond the first few performances.

The Design for Virtuosity project aims to model and repurpose the existing expertise of trained musicians, so that new creative possibilities are offered without requiring thousands of hours of retraining.


##### Understanding skills through performer-instrument models

A first focus of the project concerns the understanding of the interaction between performer and instrument leading to the development of models. Instrumental performance can be considered a special case of human-machine interaction which is interesting both for its complexity and for the common experience that the musical instrument becomes an extension of the body: while playing, the performer is often not consciously thinking about the instrument, particularly in a virtuosic performance. Controlled experiments and participatory design exercises will establish how an instrument's design affects the development of expertise, and how existing expertise can be transferred to newly-created instruments.

##### Designing new DMIs informed by the performer-instrument models

Secondly, the resulting models will inform the DMI creation process, taking a holistic approach unifying hardware design, digital signal processing, human-computer interaction (HCI) and artistic considerations. Existing DMIs often implicitly prioritise the convenience of the computer over the experience of the human player. On acoustic instruments, the entire physical object contributes to the sound, however subtly, but the choice of sensors in a DMI typically reduces the performer's actions to just a few machine-tractable dimensions. This fellowship will create instruments which deliberately oversample the interaction, using more sensors and higher sampling rates than apparently necessary, not to create a more complicated instrument, but rather to capture the subtle nuances that experts prize. Evaluation of the new DMIs will help refine the original models of performer-instrument interaction.


<!---
{% include single-image.html fileName="stock/blog-4.jpg" caption="Detailed picture of something." %}

Existing new DMI focusses: 
-Accordingly, much of current DMI research focuses on designers playing their own instruments or creating engaging experiences for nonmusicians. 
-Attempts to repurpose skills have mostly fallen short, 
given that the musical skills rely on extremely detailed understanding of the instrument's reaction to a given gestural input.

While some musicians have mastered novel instruments through extended use (Tanaka, 2000; Palacio-Quintin, 2008; Cannon and Favilla, 2012), more commonly new DMIs are set aside after only a few performances. Jordà’s statement from 2004 still rings true: “Many new instruments are being invented. Too little striking music is being made with them.”

By building on existing training, a novel DMI can potentially gain rapid access to a large expert user community. In this process of “recycling virtuosity” (Tremblay and Schwarz, 2010), interaction techniques are reused from existing training, but the end products may be completely different. However, we currently lack a general solution for how to repurpose expert skills within the musical domain. The following sections examine two obstacles: first, the interaction between performer and instrument is only partially understood, and second, most current DMI design strategies implicitly prioritise the convenience of the machine over the experience of the human player, especially in handling the subtle details that experts prize.

Essl and O’Modhrain (2006) suggest three techniques for DMIs to connect with existing expertise: augmented instruments, simulation of traditional instruments, and designs that “reappropriate instrumental gestures” to control other sounds. 

(in (1.2)) Another approach to designing for experts is to repurpose existing skills. Cook (2001) proposes the principle: “copying an instrument is dumb; leveraging expert technique is smart,” though as Jordà and Mealla (2014) point out, it remains unclear how to do this. Certain intuitive approaches are known, for example preserving a sense of energy transfer (Cadoz et al., 2000) and building on everyday tangible interactions (Essl and O’Modhrain, 2006; Rocchesso et al., 2009), but these are not specific to particular instrumental training.

A musical instrument is a tool which converts the performer’s actions to sound. A DMI typically consists of a set of electronic sensors, a sound synthesis engine, and a mapping layer that relates action to sound. 
One problem with current mapping approaches can be seen by examining dimensionality and subtlety. DMI designers often focus on the number of independent dimensions the user can control even though there is little evidence to suggest that more dimensions produce a better instrument (Tanaka, 2000). 
On the other hand, subtle differences between apparently “identical” mappings make a huge difference to performers: a Stradivarius and a cheap student violin have the exact same dimensionality and a nominally identical mapping, yet only one is suitable for virtuoso performance.

Ultimately, any mapping is limited by the detail of the electronic sensors. On an acoustic instrument, the entire physical object contributes to the sound (however subtly) and interaction is possible with any part of the object, but DMIs typically contain a few active sensors inside an otherwise passive box (Poepel, 2011).
We propose to bring new subtlety to DMIs by deliberately oversampling the interaction, using more sensors and higher bandwidth than apparently necessary, then mapping this rich sensor space down to a tractable number of dimensions while focusing on the nuances that make the best instruments stand out.

-->
